{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
      "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
      "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "Original columns in the dataset: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'] \n",
      "Columns in the describe dataset: ['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare'] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py35/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as path\n",
    "%matplotlib inline \n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "data_folder = '/Users/GraysTECH/BigQLabs/portfolio/machine-learning/kaggle-titanic/data/'\n",
    "\n",
    "files = {\"training_file\":\"train.csv\", \"testing_file\":\"test.csv\"}\n",
    "\n",
    "train_file = path.join(data_folder,files[\"training_file\"])\n",
    "test_file = path.join(data_folder,files[\"testing_file\"])\n",
    "\n",
    "#print(train_file, \"\\n\",test_file)\n",
    "\n",
    "titanic = pd.read_csv(train_file)\n",
    "print(titanic.head(5))\n",
    "print(titanic.describe())\n",
    "print(\"Original columns in the dataset: {0} \".format(titanic.columns.tolist()))\n",
    "print(\"Columns in the describe dataset: {0} \".format(titanic.describe().columns.tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values Strategy\n",
    "Notice from above that the describe method return a count of 714 for the Age column, compare that to the count of 891 for all the other columns. This means that the Age column has missing values. This means that the data isnt perfectly clean and we are going to clean it ourselves.\n",
    "We don't want to remove the rows with the missing values because more the data the more it helps us to train the algorithm better. The other option is to not consider the Age column and leave it out but that is not a good option because the age of the person might affect the chances of survival. Our strategy to address the missing value will be to assign the median values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      29.361582\n",
       "std       13.019697\n",
       "min        0.420000\n",
       "25%       22.000000\n",
       "50%       28.000000\n",
       "75%       35.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign meadian age to the Age column\n",
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin column count:  204\n"
     ]
    }
   ],
   "source": [
    "print(\"Cabin column count: \",titanic[\"Cabin\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we used describe above it's clear that not all columns were shown as part of the summary table. The missing columns had non-numerical data as a result could not be summarized, the missing columns were : Name, Sex, Cabin, Ticket, Embarked. We will ignore the Ticket, Cabin and Embarked column. There are only 204 values in the Cabin column and it likely isn't a particularly informative field. The Ticket and Embarked columns are unlikely to give us much information without the domain knowledge about what the ticket numbers represent and how do they corelate with the Name column.\n",
    "\n",
    "The Sex column is non-numeric but we want to keep it because it could be very informative. We can convert it to a numeric column by assigning unique numeric codes to the male and female categories.\n",
    "We will assign a code of 0 for male and 1 for female.\n",
    "We can select all the male values in the Sex column using\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the Sex column:  ['male' 'female']\n",
      "Unique values in the Sex column after encoding:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Find the unique values in the sex column, the reason we want to do this exercise is to find out if the there \n",
    "# are any values other than male and female assigned to the column\n",
    "\n",
    "print(\"Unique values in the Sex column: \", titanic[\"Sex\"].unique())\n",
    "\n",
    "# Encode the male and femal values in the Sex column with 0 and 1 values respectively\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "print(\"Unique values in the Sex column after encoding: \", titanic[\"Sex\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same way we can encode the values in the Embarked column to numeric codes thereby converting the text values to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the Embarked column:  ['S' 'C' 'Q' nan]\n",
      "Total frequency of the S value:  644\n",
      "Use Describe to get the summary statistics on the Embarked series after encoding:\n",
      " count     891\n",
      "unique      3\n",
      "top         0\n",
      "freq      646\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find unique values in the Embarked column\n",
    "print(\"Unique values in the Embarked column: \", titanic[\"Embarked\"].unique())\n",
    "\n",
    "print(\"Total frequency of the S value: \",titanic[titanic[\"Embarked\"]==\"S\"][\"Embarked\"].count())\n",
    "\n",
    "#print(\"Use Describe to get the summary statistics on the Embarked series:\\r\",titanic[\"Embarked\"].describe())\n",
    "\n",
    "# Notice there are nan Not a Number value associated with the certain rows, we have to fix this by assigning \n",
    "# the most common port in the dataset which is \"S\"\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('S')\n",
    "\n",
    "#print(\"Use Describe to get the summary statistics on the Embarked series after filling na's:\\n\",titanic[\"Embarked\"].describe())\n",
    "\n",
    "# We will assign the code 0 to S, 1 to C and 2 to Q\n",
    "embarked_codes = {\"S\":0, \"C\":1, \"Q\":2}\n",
    "\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "#for k,v in embarked_codes.items():\n",
    "    #titanic.loc[titanic[\"Embarked\"] == k, \"Embarked\"] == v\n",
    "    \n",
    "print(\"Use Describe to get the summary statistics on the Embarked series after encoding:\\n\",titanic[\"Embarked\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression:\n",
    "If we wanted to predict if somebody survived in the titanic crash based on their age then we could use a technique called Linear regression, the algorithm takes the form y = mx + b where m is the coefficient called the slope of the line, b is the Y intercept and x is the predictor and y is the outcome we are trying to predict.\n",
    "Linear regression is a very powerful algorithm if the data is linear corelation but it has a few downsides, for e.g. 1. If the column and the outcome is not linearly related the prediction cannot be accurate. \n",
    "2. It wont give you probabilities of the outcome only absolute probabilities.\n",
    "\n",
    "#### Cross Validation:\n",
    "We want to train the data on a different data set than we want to make the predictions on. This is critical if we want to avoid overfitting. Overfitting is what happens when the model fits itself to noise rather than signal, Every dataset has its own quirks that do not exist in the full populations. For example if you were asked to predict the top speed of a car by its horsepower and other charateristics and gave you a dataset that randomly had cars with very high speeds, the resulting model will always overstate the speed. The way to figure out if your model is doing this is to evaluate the performance of the model on data that it has not been trained on.\n",
    "\n",
    "Every Machine Learning algorithm can overfit, although linear regression is less prone to it. Cross validation is a technique used to avoid overfitting, you split the data into parts or folds, lets say 3 for example, you then do this:\n",
    "1. Combine the first two parts, train the model, make predictions on the third part.\n",
    "2. Combine the first and third parts, train the model and make predictions on the second part.\n",
    "3. Combine the second and third parts, train the modeland make predictions on the first part.\n",
    "\n",
    "This way we generate predictions on the entire dataset without ever evaluating the accuracy on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfolds:  sklearn.cross_validation.KFold(n=891, n_folds=3, shuffle=False, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions : We will be using scikit-learn to make the predictions\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sklearn has a helper class that makes it easy to do cross-validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# We will be using the following columns to preict the outcome\n",
    "predictors = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]\n",
    "\n",
    "# Initialize the algorithm\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Generate cross-validation folds for the titanic dataset. It returns row indices corresponding to the train and test\n",
    "# datsets\n",
    "# We set random_state to ensure we get the same splits everytime we execute the code\n",
    "kf = KFold(titanic.shape[0],n_folds = 3, random_state = 1)\n",
    "predictions = []\n",
    "print(\"kfolds: \",kf)\n",
    "for train, test in kf:\n",
    "    # The predictors we are using to train the algorithm, Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    # The target we are using to train our algorithm\n",
    "    train_target = (titanic[\"Survived\"].iloc[train])\n",
    "    \n",
    "    # Training the algorithm using the predictors and the target\n",
    "    linreg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = linreg.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the Performance of the model:\n",
    "Now that we have the predictions, we need to evaluate the error to measure the performance of the model. From the Kaggle Comptetition description the error metric is a percentage of correct predictions. We will use the same metric to evaluate our performance locally.\n",
    "\n",
    "The metric will basically involve in finding the number of values in predictions that have the same exact value in the titanic[\"Survived\"], then by dividing by the number of passengers.\n",
    "\n",
    "Before we do this we need to combine the 3 sets of predictions into 1 column. Since each set of predictions is a numpy array, we can use a numpy function concatenate them into one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7833894500561167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:10: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]])/len(predictions)\n",
    "print(\"Accuracy: {0}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our first predictions! The accuracy is not that great it's about 78.3%. To improve the accuracy we will use Logistic Regression to instead output values between 0 and 1. One good way to think about the logistic regression is that it takes the output of the linear regression and maps it into a probability between 0 and 1. The mapping is done by the logit function. Passing any value to the logit function will map it to a value between 0 and 1 by squeezing the extreme values. This is good for us since we only care about two outcomes.\n",
    "\n",
    "sklearn has a class for logistic regression that we can use. We will also make things easier by using an sklearn helper function to do all of our cross-validation and evaluation for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78451178  0.78787879  0.79124579]\n",
      "0.787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Initialize our algorithm\n",
    "alg = LogisticRegression(random_state = 1)\n",
    "\n",
    "#Compute the accuracy scores for all the cross-validation folds.\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print(scores)\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the Test dataset and predict the survival of the passenger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in test set: (418, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py35/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    417.000000\n",
       "mean      35.627188\n",
       "std       55.907576\n",
       "min        0.000000\n",
       "25%             NaN\n",
       "50%             NaN\n",
       "75%             NaN\n",
       "max      512.329200\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test = pd.read_csv(test_file)\n",
    "\n",
    "# assign meadian age to the Age column\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic_test[\"Age\"].median())\n",
    "\n",
    "# Encode the male and femal values in the Sex column with 0 and 1 values respectively\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "# Notice there are nan Not a Number value associated with the certain rows, we have to fix this by assigning \n",
    "# the most common port in the dataset which is \"S\"\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "print(\"Total records in test set: {0}\".format(titanic_test.shape))\n",
    "titanic_test.describe()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
