{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "To understand how linear regression works, we've stuck to using features from the training dataset that contained no missing values and were already in convenient numeric representation. In this notebook, we'' explore how to transform some of the remaining features so we can use them in our model. Broadly, the process of processing and creating new features is known as [feature engineering](https://en.wikipedia.org/wiki/Feature_engineering). Feature engineering is a bit of an art and having knowledge  in the specific domain (in this case real estate) can help you create better features. In this mission, we'' focus on some domain-independent strategies that work for all problems.\n",
    "\n",
    "In the first half of this mission, we'll focus only on columns that contain no missing values but still aren't in the proper format to use in a linear regression model. In the latter half of this mission, we'll explore some ways to deal with missing values.\n",
    "\n",
    "Amongst the columns that don't contain missing values, some of the common issues include:\n",
    "- The column is not numerical (e.g. a zoning code represented using text)\n",
    "- The column is numerical but not ordinal (e.g. zip code values)\n",
    "- The column is numerical but isn't representative of the type of relationship with the target column (e.g. year values)\n",
    "\n",
    "Let's start by filtering the training set to just the columns containing no missing values.\n",
    "\n",
    "#### Instructions\n",
    "- Select just the columns from the train data frame that contain no missing values.\n",
    "- Assign the resulting data frame, that contains just these columns, to df_no_mv.\n",
    "- Use the variables display to become familiar with these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2930"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('AmesHousing.txt', delimiter=\"\\t\")\n",
    "target='SalePrice'\n",
    "total_records = len(data)\n",
    "total_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>...</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Area Street Lot Shape  \\\n",
       "0      1  526301100           20        RL     31770   Pave       IR1   \n",
       "1      2  526350040           20        RH     11622   Pave       Reg   \n",
       "2      3  526351010           20        RL     14267   Pave       IR1   \n",
       "3      4  526353030           20        RL     11160   Pave       Reg   \n",
       "\n",
       "  Land Contour Utilities Lot Config    ...     Enclosed Porch 3Ssn Porch  \\\n",
       "0          Lvl    AllPub     Corner    ...                  0          0   \n",
       "1          Lvl    AllPub     Inside    ...                  0          0   \n",
       "2          Lvl    AllPub     Corner    ...                  0          0   \n",
       "3          Lvl    AllPub     Corner    ...                  0          0   \n",
       "\n",
       "  Screen Porch Pool Area Misc Val Mo Sold  Yr Sold  Sale Type  Sale Condition  \\\n",
       "0            0         0        0       5     2010        WD           Normal   \n",
       "1          120         0        0       6     2010        WD           Normal   \n",
       "2            0         0    12500       6     2010        WD           Normal   \n",
       "3            0         0        0       4     2010        WD           Normal   \n",
       "\n",
       "   SalePrice  \n",
       "0     215000  \n",
       "1     105000  \n",
       "2     172000  \n",
       "3     244000  \n",
       "\n",
       "[4 rows x 58 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign approx 50% of the data to train and 50% to test\n",
    "train = data[0:1460]\n",
    "test = data[1460:]\n",
    "\n",
    "train_null_counts = train.isnull().sum()\n",
    "no_mv_cols = train_null_counts[train_null_counts == 0]\n",
    "\n",
    "df_no_mv = train[no_mv_cols.index]\n",
    "df_no_mv.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the columns in the data frame df_no_mv contain string values. If these columns contain only a limited set of unique values, they are known as categorical features. As the name suggests, a categorical feature groups a specific training example into a specific category. Here are some examples from the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AllPub    1457\n",
       "NoSewr       2\n",
       "NoSeWa       1\n",
       "Name: Utilities, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Utilities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pave    1455\n",
       "Grvl       5\n",
       "Name: Street, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Street'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1Story    743\n",
       "2Story    440\n",
       "1.5Fin    160\n",
       "SLvl       60\n",
       "SFoyer     35\n",
       "2.5Unf     11\n",
       "1.5Unf      8\n",
       "2.5Fin      3\n",
       "Name: House Style, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['House Style'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use these features in our model, we need to transform them into numerical representations. Thankfully, pandas makes this easy because the library has a special [categorical data type](https://pandas.pydata.org/pandas-docs/stable/categorical.html). We can convert any column that contains no missing values to the categorical data type using the pandas.Series.astype() method.\n",
    "\n",
    "```\n",
    ">>> train['Utilities'] = train['Utilities'].astype('category')\n",
    "```\n",
    "\n",
    "When a column is converted to the categorical data type, pandas assigns a code to each unique value in the common. Unless we access these values directly, most of the pandas manipulation operations that work for string columns will work for categorical ones as well.\n",
    "\n",
    "We need to use the .cat accessor followed by the .codes property to actually access the underlying numerical representation of a column:\n",
    "\n",
    "```\n",
    ">>> train['Utilities'].cat.codes\n",
    "```\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Convert all of the text columns in train to the categorical data type.\n",
    "- Select the Utilities column, return the categorical codes, and display the unique value counts for those codes: - train['Utilities'].cat.codes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1457\n",
       "2       2\n",
       "1       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cols = df_no_mv.select_dtypes(include=['object']).columns\n",
    "for col in text_cols:\n",
    "    train[col] = train[col].astype('category')\n",
    "\n",
    "train['Utilities'].cat.codes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AllPub, NoSewr, NoSeWa]\n",
       "Categories (3, object): [AllPub, NoSewr, NoSeWa]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Utilities'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When we convert a column to the categorical data type, pandas assigns a number from 0 to n-1 (where n is the number of unique values in a column) for each value. The drawback with this approach is that one of the assumptions of linear regression is violated here. Linear regression operates under the assumption that the features are linearly correlated with the target column. For a categorical feature, however, there's no actual numerical meaning to the categorical codes that pandas assigned for that colum. An increase in the Utilities column from 1 to 2 has no correlation value with the target column, and the categorical codes are instead used for uniqueness and exclusivity (the category associated with 0 is different than the one associated with 1).\n",
    "\n",
    "The common solution is to use a technique called dummy coding. Instead of having a single column with n integer codes, we have n binary columns. Here's what that would look like for the Utilities column:\n",
    "\n",
    "| Utilities_AllPub | Utilities_NoSewr | Utilities_NoSeWa |\n",
    "|:----------------:|:----------------:|:----------------:|\n",
    "|    1             |       0          |       0          |\n",
    "|    1             |       0          |       0          |\n",
    "|    1             |       0          |       0          |\n",
    "|    1             |       0          |       0          |\n",
    "\n",
    "Because the original values for the first 4 rows were AllPub, in the new scheme, they contain the binary value for true (1) in the Utilities_AllPub column and 0 for the other 2 columns.\n",
    "\n",
    "Pandas thankfully has a convenience method to help us apply this transformation for all of the text columns called [pandas.get_dummies()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html):\n",
    "\n",
    "```\n",
    "dummy_cols = pd.get_dummies()\n",
    "```\n",
    "\n",
    "#### Instructions\n",
    "- Convert all of the columns in text_cols from the train data frame into dummy columns.\n",
    "- Delete the original columns from text_cols from the train data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in text_cols:\n",
    "    col_dummies = pd.get_dummies(train[col])\n",
    "    train = pd.concat([train,col_dummies],axis=1)\n",
    "    del train[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last few screens, we focused on categorical values that were represented as text columns. Some of the numerical columns in the data set are also categorical and only have a limited set of unique values. We won't explicitly explore those coumns in this mission, but the feature transformation process is the same if the numbers used in those categories have no numerical meaning.\n",
    "\n",
    "Let's now look at numerical features that aren't categorical, but whose numerical representation needs to be improved. We'll focus on the Year Remod/Add and Year Built columns:\n",
    "\n",
    "```\n",
    ">>> train[['Year Remod/Add', 'Year Built']]\n",
    "```\n",
    "| 0  | 1960 | 1960 |\n",
    "|:--:|:----:|:----:|\n",
    "|1   |1961  | 1961 |\n",
    "|2   |1958  | 1958 |\n",
    "|3   |1968  | 1968 |\n",
    "|4   |1998  | 1997 |  \n",
    "...\n",
    "The two main issues with these features are:\n",
    "\n",
    "Year values aren't representative of how old a house is\n",
    "The Year Remod/Add column doesn't actually provide useful information for a linear regression model\n",
    "The challenge with year values like 1960 and 1961 is that they don't do a good capture how old a house is. For example, a house that was built in 1960 but sold in 1980 was sold in half the time one built in 1960 and sold in 2000. Instead of the years certain events happened, we want the difference between those years. We should create a new column that's the difference between both of these columns.\n",
    "\n",
    "For this particular piece of information (years until remodeled), this is a sensible approach. Domain knowledge can help you understand how to best transform features to represent information well for a linear model. If you're ever confused about a feature or how it should be represented, reading scientific papers or posts by researchers in the specific domain is critical. Many winners of Kaggle data science competitions, for example, claim that their focus on data preparation and feature engineering combined with common machine learning models helped them win.\n",
    "\n",
    "#### Instructions\n",
    "- Create a new column years_until_remod in the train data frame that represents the difference between Year Remod/Add (the later value) and Year Built (the earlier value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"years_until_remod\"] = train['Year Remod/Add'] - train['Year Built']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next few screens, we'll focus on handling columns with missing values. When values are missing in a column, there are two main approaches we can take:\n",
    "\n",
    "- Remove rows containing missing values for specific columns\n",
    "  - Pro: Rows containing missing values are removed, leaving only clean data for modeling\n",
    "  - Con: Entire observations from the training set are removed, which can reduce overall prediction accuracy\n",
    "- Impute (or replace) missing values using a descriptive statistic from the column\n",
    "  - Pro: Missing values are replaced with potentially similar estimates, preserving the rest of the observation in the model.\n",
    "  - Con: Depending on the approach, we may be adding noisy data for the model to learn\n",
    "  \n",
    "Given that we only have 1460 training examples (with ~80 potentially useful features), we don't want to remove any of these rows from the dataset. Let's instead focus on imputation techniques.\n",
    "\n",
    "We'll focus on columns that contain at least 1 missing value but less than 365 missing values (or 25% of the number of rows in the training set). There's no strict threshold, and many people instead use a 50% cutoff (if half the values in a column are missing, it's automatically dropped). Having some domain knowledge can help with determining an acceptable cutoff value.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Select only the columns from train that contain more than 0 missing values but less than 584 missing values. Assign the resulting data frame to df_missing_values.\n",
    "- Display the number of missing values for each column in df_missing_values.\n",
    "- Display the data type for each column in df_missing_values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lot Frontage      249\n",
      "Mas Vnr Type       11\n",
      "Mas Vnr Area       11\n",
      "Bsmt Qual          40\n",
      "Bsmt Cond          40\n",
      "Bsmt Exposure      41\n",
      "BsmtFin Type 1     40\n",
      "BsmtFin SF 1        1\n",
      "BsmtFin Type 2     41\n",
      "BsmtFin SF 2        1\n",
      "Bsmt Unf SF         1\n",
      "Total Bsmt SF       1\n",
      "Bsmt Full Bath      1\n",
      "Bsmt Half Bath      1\n",
      "Garage Type        74\n",
      "Garage Yr Blt      75\n",
      "Garage Finish      75\n",
      "Garage Qual        75\n",
      "Garage Cond        75\n",
      "dtype: int64\n",
      "Lot Frontage      float64\n",
      "Mas Vnr Type       object\n",
      "Mas Vnr Area      float64\n",
      "Bsmt Qual          object\n",
      "Bsmt Cond          object\n",
      "Bsmt Exposure      object\n",
      "BsmtFin Type 1     object\n",
      "BsmtFin SF 1      float64\n",
      "BsmtFin Type 2     object\n",
      "BsmtFin SF 2      float64\n",
      "Bsmt Unf SF       float64\n",
      "Total Bsmt SF     float64\n",
      "Bsmt Full Bath    float64\n",
      "Bsmt Half Bath    float64\n",
      "Garage Type        object\n",
      "Garage Yr Blt     float64\n",
      "Garage Finish      object\n",
      "Garage Qual        object\n",
      "Garage Cond        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('AmesHousing.txt', delimiter=\"\\t\")\n",
    "train = data[0:1460]\n",
    "test = data[1460:]\n",
    "\n",
    "train_null_counts = train.isnull().sum()\n",
    "\n",
    "df_missing_values = train[train_null_counts[ (train_null_counts > 0) & (train_null_counts<584)].index]\n",
    "\n",
    "print(df_missing_values.isnull().sum())\n",
    "print(df_missing_values.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like about half of the columns in df_missing_values are string columns (object data type), while about half are float64 columns. For numerical columns with missing values, a common strategy is to compute the mean, median, or mode of each column and replace all missing values in that column with that value.\n",
    "\n",
    "Because imputation is a common task, pandas contains a method named pandas.DataFrame.fillna() that we can use for this. If we pass in a value, all of the missing values (NaN) in the data frame are replaced by that value.\n",
    "\n",
    "#### Instructions\n",
    "- Impute the missing values from float_cols with the column's mean.\n",
    "- Check for any missing values in float_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lot Frontage      0\n",
      "Mas Vnr Area      0\n",
      "BsmtFin SF 1      0\n",
      "BsmtFin SF 2      0\n",
      "Bsmt Unf SF       0\n",
      "Total Bsmt SF     0\n",
      "Bsmt Full Bath    0\n",
      "Bsmt Half Bath    0\n",
      "Garage Yr Blt     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "float_cols = df_missing_values.select_dtypes(include=['float'])\n",
    "float_cols = float_cols.fillna(df_missing_values.mean())\n",
    "print(float_cols.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
